### Hi there ðŸ¤–

I'm a Junior Data Scientist, and currently committing to an MSc. in Applied Data Science. In my repositories, you'd see various projects I personally developed. I also deploy some of my projects on Streamlit.   

## Languages and Tools

Here are some of the languages and tools I work with:

- Python
- Streamlit
- NoSQL
- Scikit-learn
  - Preprocessing
  - Imputation Methods
  - Modelling
    - XGBM, LightGBM, Stochastic Gradient Boosting.
  - Pipeline
- Deep Neural Networks
  - Tensorflow & Keras (Functional API & Sequential API)
    - Model Building
      - Recurrent Neural Networks (GRU, LSTM, Bidirectional LSTM)
        - Dropout, Layer Normalization, Residual Connections   
      - Convolutional Neural Networks
        - Dropout, Batch Normalization, Residual Connections 
- SpaCy
- Optuna Optimization
- SHAP

## My Projects

Here are a few notable projects I have worked on:

- [Bank Customer Deposit Prediction](https://github.com/dfavenfre/customer_deposit_classifier): Streamlit app developed for bank customer deposit prediction, using a fine-tuned XGBClassifier model.
- [Forecasting Hourly Electricity Prices](https://github.com/dfavenfre/electricity-price-forecasting): Developed various models to forecast hourly electricity prices provided by the EXIST Market Transparency Platform.
- [Econ Dashboard](https://github.com/dfavenfre/Econ-Dashboard): Econ-Dashboard is a centralized financial dashboard for financial/economic data screening, sentiment classification and time-series forecasting
- [Financial Sentiment Classifier](https://github.com/dfavenfre/financial-sentiment-classifier): Model_USE is a pre-trained NLP model to analyze the sentiment of financial or economic commentary, tweet, or news. It is built upon Universal Sentence Encoder (USE) and fine-tuned for financial sentiment classification purposes. Financial Phrasebank's 'agreeall' dataset was used for fine-tuning.

## Connect with Me
You can find me on different platforms:

- [Kaggle](https://www.kaggle.com/dfavenfre/code)
- [LinkedIn](www.linkedin.com/in/tolga-ÅŸakar-575b86136)
- [Medium](https://medium.com/@bauglir)
- [HuggingFace repository](https://huggingface.co/dfavenfre/model_use)

Feel free to reach out to me on any of these platforms. I'm always excited to connect with fellow developers, researchers, and enthusiasts.

## Medium Blogs
I occasionally write blog posts on various topics at [Medium](https://medium.com/@bauglir). Here are some of my recent articles:

- [Leveraging Lagged Exogenous Variables For Time-Series Forecasting â€” Without Time](https://medium.com/@bauglir/leveraging-lagged-exogenous-variables-for-time-series-forecasting-without-time-472f14acb488)
  I explore additional usage of ML models to forecast (t+n) horizons with lagged exogenous variables. On top of that, I deploy a neural network time-series model to create a benchmark for later comparison, using nn.LSTM layers.

- [House Price Prediction: Stochastic Gradient Boosting With KNN Imputer for Pre-processing](https://medium.com/@bauglir/house-price-prediction-stochastic-gradient-boosting-w-knn-imputer-pre-processing-f3d1651caa00):
  A depth-analysis on Kaggle's House price prediction competition, along with my submission. Within this medium blog, I explore the usage of KNNImputer for missing value imputations, engineer some features, build a model using Stochastic Gradient Boost, conduct hyperparameter tuning deploying Optuna and finaly, I evaluate feature selection based on SHAP algorithm.
       
- [Credit Score Prediction With Multi-Model Ensemble Voting Classifier](https://medium.com/@bauglir/credit-score-prediction-with-multi-model-ensemble-voting-classifier-80-accuracy-b091f929ad40)
  I share a detailed-out process starting from cleaning and interpolating to building a voting-classifier as an introduction to building a classification model, using various machine learning algorithms.
